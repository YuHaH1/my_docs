---
lang: zh-CN
title: 计算机网络
description: 关键功能
collapsible: true
---
# 计算机网络

## 一、http



### 1.缓存



#### Cache-Control

**`Cache-Control`** 通用消息头字段，被用于在 http 请求和响应中，通过指定指令来实现缓存机制。缓存指令是单向的，这意味着在请求中设置的指令，不一定被包含在响应中。

**客户端指令**

~~~txt
Cache-Control: max-age=<seconds>
Cache-Control: max-stale[=<seconds>]
Cache-Control: min-fresh=<seconds>
Cache-control: no-cache
Cache-control: no-store
Cache-control: no-transform
Cache-control: only-if-cached
~~~

**服务端指令**

~~~txt
Cache-control: must-revalidate
Cache-control: no-cache
Cache-control: no-store
Cache-control: no-transform
Cache-control: public
Cache-control: private
Cache-control: proxy-revalidate
Cache-Control: max-age=<seconds>
Cache-control: s-maxage=<seconds>
~~~

#### 可缓存性指令

**`public`**

表明响应可以被任何对象（包括：发送请求的客户端，代理服务器，等等）缓存，即使是通常不可缓存的内容。（例如：1.该响应没有`max-age`指令或`Expires`消息头；2. 该响应对应的请求方法是 [POST](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/POST) 。）

`private`

表明响应只能被单个用户缓存,不能被代理服务器缓存，不能作为共享缓存（即代理服务器不能缓存它）。私有缓存可以缓存响应内容，比如：对应用户的本地浏览器。

`no-cache`

在发布缓存副本之前，强制要求缓存把请求提交给原始服务器进行验证 (协商缓存验证)。

`no-store`

缓存不应存储有关客户端请求或服务器响应的任何内容，即不使用任何缓存。

**例如：**

`Cache-Control: no-store`发送如下响应头可以关闭缓存。

`Cache-Control:public, max-age=31536000`这个头部信息告诉客户端和代理服务器可以缓存响应，并且可以将缓存的响应保留一年。

`Cache-Control: no-cache`和`Cache-Control: max-age=0, must-revalidate`指定 `no-cache` 或 `max-age=0, must-revalidate` 表示客户端可以缓存资源，每次使用缓存资源前都必须重新验证其有效性。这意味着每次都会发起 HTTP 请求，但当缓存内容仍有效时可以跳过 HTTP 响应体的下载。

**共享缓存是什么？**共享缓存是指多个客户端或代理服务器可以共同使用的缓存，例如代理服务器缓存或 CDN（内容分发网络）缓存。



#### 到期指令

`max-age=<seconds>`

设置缓存存储的最大周期，超过这个时间缓存被认为过期 (单位秒)。与`Expires`相反，时间是相对于请求的时间。

`s-maxage=<seconds>`

设置缓存存储的最大周期，超过这个时间缓存被认为过期 (单位秒)。与`Expires`相反，时间是相对于请求的时间。

`max-stale[=<seconds>]`

表明客户端愿意接收一个已经过期的资源。可以设置一个可选的秒数，表示响应不能已经过时超过该给定的时间。

`min-fresh=<seconds>`

表示客户端希望获取一个能在指定的秒数内保持其最新状态的响应。



### 2.缓存验证 （协商缓存/强缓存）

**强缓存**：浏览器不会像服务器发送任何请求，直接从本地缓存中读取文件并返回`Status Code: 200 form memory cache/from disk cache`优先访问memory cache,其次是disk cache，最后是请求网络资源

> 200 form memory cache : 不访问服务器，一般已经加载过该资源且缓存在了内存当中，直接从内存中读取缓存。浏览器关闭后，数据将不存在（资源被释放掉了），再次打开相同的页面时，不会出现from memory cache。

> 200 from disk cache： 不访问服务器，已经在之前的某个时间加载过该资源，直接从硬盘中读取缓存，关闭浏览器后，数据依然存在，此资源不会随着该页面的关闭而释放掉下次打开仍然会是from disk cache。

**协商缓存**: 向服务器发送请求，服务器会根据这个请求的`request header`的一些参数来判断是否命中协商缓存，如果命中，则返回304状态码并带上新的response header通知浏览器从缓存中读取资源；

根据哪些判断强缓存？

`Expires`：过期时间，如果设置了时间，则浏览器会在设置的时间内直接读取缓存，不再请求，告诉浏览器缓存有效期的绝对时间<u>，权重小于`max-age`</u>

`Cache-Control`：当值设为`max-age=300`时，则代表在这个请求正确返回时间（浏览器也会记录下来）的5分钟内再次加载资源，就会命中强缓存。

`cache-control`：除了该字段外，还有几个比较常用的设置值详情看上一章

如何协商缓存？

`Last-Modifed/If-Modified-Since和Etag/If-None-Match`是分别成对出现的，呈一一对应关系

#### 1.Last-Modified / If-Modified-Since

过时的响应不会立即被丢弃。HTTP 有一种机制，可以通过询问源服务器将陈旧的响应转换为新的响应。这称为**验证**，有时也称为**重新验证**。验证是通过使用包含 `If-Modified-Since` 或 `If-None-Match` 请求标头的**条件请求**完成的。

服务器响应头中包含 `Last-Modified` 字段，表示资源最后一次修改的时间，客户端在下一次请求时，会在请求头中添加 `If-Modified-Since` 字段，值为上一次缓存的 `Last-Modified` 时间。如果服务器检测到资源自上次缓存以来未发生更改，则返回 `304 Not Modified` 响应码，告诉客户端可以直接使用缓存的响应。这也成为**协商缓存**

以下响应在 22:22:22 生成，`max-age` 为 1 小时，因此你知道它在 23:22:22 之前是新鲜的。

```http
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600
```

到 23:22:22 时，响应会过时并且不能重用缓存。因此，下面的请求显示客户端发送带有 `If-Modified-Since` 请求标头的请求，以询问服务器自指定时间以来是否有任何的改变。

~~~http
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Tue, 22 Feb 2022 22:00:00 GMT
~~~

如果内容自指定时间以来没有更改，服务器将响应 `304 Not Modified`。由于此响应仅表示“没有变化”，因此没有响应主体——只有一个状态码——因此传输大小非常小。收到该响应后，客户端将存储的陈旧响应恢复为新鲜的，并可以在剩余的 1 小时内重复使用它。

~~~http
HTTP/1.1 304 Not Modified
Content-Type: text/html
Date: Tue, 22 Feb 2022 23:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600
~~~

#### 2.ETag/if-None-Match

**ETag 的权重高于 Last-Modified**

由于`Last-Modified / If-Modified-Since`存在一些问题；例如，时间格式复杂且难以解析，分布式服务器难以同步文件更新时间,Last-Modified只能精确到秒级别，对于一些快速变化的资源，可能会出现两次请求之间资源已经被修改，但是Last-Modified时间却未被更新的情况，以及资源的内容可能没有变化，但最后修改时间却更新了，比如只是修改了资源的元数据。而ETag则可以更准确地标识资源的版本和修改时间，从而避免这些问题。

同时，ETag还可以用于分布式服务器环境中的缓存控制。在分布式环境中，由于多台服务器负责处理请求，使用Last-Modified进行缓存控制可能会出现不一致的情况。而使用ETag则可以避免这些问题，因为ETag是在服务器端生成的唯一标识符，不受服务器数量和负载均衡的影响。。为了解决这些问题，`ETag` 响应标头被标准化作为替代方案。

`ETag` 响应标头的值是服务器生成的任意值。服务器对于生成值没有任何限制，因此服务器可以根据他们选择的任何方式自由设置值——例如主体内容的哈希或版本号。

例如

~~~http
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
ETag: "deadbeef"
Cache-Control: max-age=3600
~~~

如果该响应是旧的，则客户端获取缓存响应的 `ETag` 响应标头的值，并将其放入 `If-None-Match` 请求标头中，以询问服务器资源是否已被修改：

~~~http
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "deadbeef"
~~~

如果服务器为请求的资源确定的 `ETag` 标头的值与请求中的 `If-None-Match` 值相同，则服务器将返回 `304 Not Modified`。

但是，如果服务器确定请求的资源现在应该具有不同的 `ETag` 值，则服务器将其改为 `200 OK` 和资源的最新版本进行响应。

### 3.缓存位置

在chrome浏览器中的控制台Network中size栏通常会有三种状态：

1.from memory cache

2.from disk cache

3.资源本身的大小(如：1.5k)

1. Memory Cache（内存缓存）：顾名思义，内存缓存即将请求过的资源保存在内存中，是浏览器中最快的缓存机制。当浏览器需要请求资源时，会先在内存缓存中查找，如果找到了并且资源没有过期，则直接返回内存中的资源，否则向下一级缓存（例如磁盘缓存）继续查找。内存缓存的优点是读取速度快，缺点是容量较小，只能缓存一些常用的资源，且浏览器进程关闭资源就释放了。
2. Disk Cache（磁盘缓存）：磁盘缓存是将请求过的资源保存在本地硬盘或闪存中，相比内存缓存容量较大，可以缓存更多的资源。当浏览器需要请求资源时，会先在内存缓存中查找，如果没有找到或者找到但已经过期，则向磁盘缓存中查找。磁盘缓存的优点是容量大，能够缓存较多的资源，缺点是读取速度相对较慢。
3. Service Worker（服务工作线程）缓存：Service Worker 是一种独立于浏览器窗口的 JavaScript 线程，在浏览器后台运行。它可以拦截浏览器发出的网络请求，从而可以实现离线缓存、推送通知等功能。Service Worker 缓存可以将请求过的资源保存在本地，不受浏览器的关闭或页面刷新的影响。当用户下一次访问同样的页面时，Service Worker 可以直接从本地缓存中获取资源，从而提高页面加载速度和离线访问体验。



### 2.http1.0-3.0区别

#### htpp/1.0

1.0的http是无连接的应用层协议：浏览器每次请求都需要建立tcp连接

因此其缺点十分明显

* 无法复用连接。每次发送请求的时候，都需要进行一次[TCP连接](#tcp)，而TCP的连接释放过程又是比较费事的。这种无连接的特性会导致网络的利用率非常低。
* 队头堵塞(head of line blocking)。由于HTTP/1.0规定下一个请求必须在前一个请求响应到达之前才能发送。假设一个请求响应一直不到达，那么下一个请求就不发送，就到导致阻塞后面的请求。
* 每个连接只能处理一个请求，因此需要不断地打开和关闭连接，使得性能较慢。
* 只支持文本数据：HTTP/1.0只支持文本数据的传输，对于非文本数据（如图片、视频、音频等）需要使用其他协议进行传输。

#### http/1.1

为了解决1.0的问题采用以下方法

* **持久连接：**通过设置`Keep-alive`字段开启长连接，避免了每次客户端与服务器请求都要重复建立释放TCP连接，提高了网络的利用率。如果客户端想关闭HTTP连接，可以在请求头中携带`Connection:false`来告知服务器关闭请求
* **分块传输编码：**允许服务器在传输数据时将数据分成多个块，每个块都包含大小信息，这样可以在传输大文件时避免等待整个文件传输完毕才能开始处理。
* **虚拟主机：**允许在同一台服务器上运行多个网站，并使用不同的域名进行访问，提高了服务器的利用率。
* **缓存控制：**允许服务器和客户端控制缓存的行为，避免了不必要的网络流量和延迟。
* **支持管道化：**允许客户端在不等待响应的情况下发送多个请求，从而提高了并发性和性能。

缺点还无法很好解决对头阻塞

::: tip

服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。所以一旦a请求由于延迟没法送到服务端，则后面的请求面部被阻塞。

:::

#### http/2.0

**帧：** HTTP/2 数据通信的最小单位消息：指 HTTP/2 中逻辑上的 HTTP 消息。例如请求和响应等，消息由一个或多个帧组成。

**流：** 存在于连接中的一个虚拟通道。流可以承载双向消息，每个流都有一个唯一的整数ID。

**消息：** 与逻辑消息对应的完整的一系列数据帧。

http/2.0有如下特点：

1. 二进制协议（二进制分帧）：HTTP/2.0采用二进制协议，在传输数据时将数据分成二进制帧（Frame）进行传输，而不是像HTTP/1.x那样使用文本协议，这样可以提高传输的效率和可靠性。
2. **多路复用**：HTTP/2.0允许在同一连接上同时传输多个请求和响应，这样可以避免HTTP/1.x中的队头阻塞问题，从而提高了性能。
3. **首部压缩**：HTTP/2.0使用首部压缩（Header Compression）来减少传输的数据量，这样可以减少网络流量和延迟，提高性能。HTTP/1.x中，每个请求和响应都包含了大量的头部信息，这些信息通常是重复的，但却需要重复传输，浪费了网络带宽和传输时间。
4. **服务器推送：**HTTP/2.0允许服务器在响应一个请求时主动推送其他资源，这样可以避免客户端发送多个请求获取所有资源，从而提高性能。
5. **流量控制：**HTTP/2.0引入了流量控制（Flow Control）机制，允许客户端和服务器动态调整传输流量，避免了拥塞和网络阻塞。
6. **安全性：**HTTP/2.0默认使用TLS加密，这样可以保护数据的安全性，防止数据被窃取或篡改。

#### 二进制分帧的优点：

* 提高效率：二进制帧可以更高效地传输数据，因为二进制数据比文本数据更紧凑，能够减少传输的数据量，从而提高传输效率。
* 更好的可靠性：二进制帧采用了更先进的错误检测和纠正机制，能够更好地检测和纠正传输过程中的错误，提高了传输的可靠性。具体来说，<u>帧头部分包含了帧的长度和类型等信息，因此可以检测出帧是否被截断或者被篡改，帧头部分还包含了帧的标识符，这个标识符可以用于检测和纠正重复的帧，每个帧都有一个校验和字段，可以用于检测帧在传输过程中是否发生了错误。一旦发生错误HTTP/2.0会向对端发送一个RST_STREAM帧，通知对端取消该帧的传输，并进行相应的错误处理，例如关闭连接或者重新发送该帧。</u>
* 支持多路复用：二进制帧的一个重要特点是支持多路复用（Multiplexing），即在同一连接上同时传输多个请求和响应，这样可以避免HTTP/1.x中的队头阻塞问题，从而提高了性能。
* 更好的扩展性：二进制帧的采用使得HTTP/2.0更容易扩展，因为可以通过定义新的帧类型来添加新的功能，而不必修改HTTP/2.0协议本身。

#### 多路复用？

* 流与帧：HTTP/2.0将每个请求和响应流分成多个二进制帧（Frame）进行传输，每个帧都包含了流标识符，用于标识一个请求或响应流。通过流标识符，HTTP/2.0可以将多个请求和响应流复用在同一个TCP连接中。
* 流优先级：HTTP/2.0允许在每个流中设置优先级，通过优先级可以控制每个流在传输过程中的相对权重。这样可以避免某些低优先级的流阻塞了高优先级的流，从而提高了传输的效率。
* 窗口控制：HTTP/2.0引入了流量控制（Flow Control）机制，允许客户端和服务器动态调整传输流量，避免了拥塞和网络阻塞。每个流都有自己的流量控制窗口，通过调整窗口大小可以控制每个流在传输过程中的速度。
* 头部压缩：HTTP/2.0使用首部压缩（Header Compression）来减少传输的数据量，这样可以减少网络流量和延迟，提高性能。采用头部压缩可以将每个请求和响应的头部信息压缩成更小的二进制数据，从而节省了网络带宽。

#### 头部压缩

HTTP/2.0中的首部压缩采用了HPACK压缩算法，它通过建立一个静态表和一个动态表来实现压缩。静态表包含了一些常用的头部字段和值的编码，可以直接使用。动态表由客户端和服务器共同维护，用于存储一些动态生成的头部字段和值，这些字段和值可以使用索引进行编码和解码。

在首部压缩的过程中，客户端和服务器会将头部信息分成头部名和头部值两部分，然后分别对它们进行编码。编码后的头部名和头部值可以使用索引进行传输，这样可以大大减少传输的数据量。在接收端，客户端和服务器会根据索引解码头部名和头部值，并将它们重新组合成完整的头部信息。

#### 流量控制

在HTTP/2.0中，每个流都有自己的流量控制窗口，通过调整窗口大小可以控制每个流在传输过程中的速度。

具体来说，每个流都有一个接收窗口和一个发送窗口。接收窗口用于控制接收端的传输速度，发送窗口用于控制发送端的传输速度。在传输过程中，每个端点都会根据当前窗口大小和已经传输的数据量来动态调整窗口大小，尽可能地利用可用的带宽，并避免拥塞和网络阻塞。

当接收端的接收窗口变小时，它会向对端发送一个WINDOW_UPDATE帧，通知对端减少传输窗口大小，从而控制发送速度。当发送端的发送窗口变小时，它会停止发送数据，并等待接收端发送WINDOW_UPDATE帧，通知它可以继续发送数据。

### 2.0仍然存在的问题

* **对头阻塞：**HTTP/2.0中的流（Stream）是有优先级的，而且流之间是串行传输的。具体来说，当一个流被阻塞时，后面的所有流都必须等待当前流的传输完成才能开始传输。如果前面的流优先级较高，传输时间较长，那么后面的流就会被阻塞，导致队头阻塞问题。虽然HTTP/2.0采用了优先级机制和流量控制机制来解决队头阻塞问题，但是这些机制并不能完全避免队头阻塞问题的发生。一些不恰当的优先级设置和流量控制机制的错误使用，也会导致队头阻塞问题的发生。
* 每次建立/释放连接仍然要经过三次握手 四次挥手

### http/3.0

3.0解决了什么问题？

* 降低延迟：TCP协议需要进行三次握手和四次挥手等过程，导致延迟较高。而QUIC协议基于UDP协议实现，可以避免这些过程，从而降低延迟。
* 提高可靠性：QUIC协议具有更好的拥塞控制能力和快速恢复机制，可以提高传输的可靠性。
* 避免队头阻塞：QUIC协议采用了多路复用和流量控制机制，避免了HTTP/1.x和HTTP/2.0中的队头阻塞问题，提高了性能。

HTTP/3.0是基于QUIC协议的下一代HTTP协议，旨在提高性能和安全性。相比于HTTP/2.0，HTTP/3.0采用了全新的传输协议QUIC（Quick UDP Internet Connections），这个协议基于UDP协议实现，具有更低的延迟和更好的拥塞控制能力，可以提高性能和可靠性。

HTTP/3.0的主要特点包括：

1. **基于QUIC协议：**HTTP/3.0采用了基于UDP协议的QUIC协议作为传输协议，可以提高性能和可靠性。
2. **支持多路复用：**HTTP/3.0支持多路复用，可以在同一连接上同时进行多个HTTP请求和响应，提高性能。基本和2.0相同。
3. **首部压缩：**HTTP/3.0采用了首部压缩机制，可以减少网络带宽的使用和传输时间，提高性能这里的压缩算法与2.0基本相同。
4. **流量控制：**QUIC协议采用了更先进的拥塞控制算法，可以更精确地控制传输速度和窗口大小，避免拥塞和网络阻塞，提高传输效率和可靠性。
5. **快速恢复：**HTTP/3.0支持快速恢复机制，可以在网络中断后更快地恢复连接和传输，提高可靠性。

#### 快恢复

HTTP/3.0采用的基于QUIC协议的传输协议支持快速恢复机制，可以更快地恢复连接和传输，提高可靠性。

1. **使用Packet Number：**QUIC协议中每个数据包都有一个Packet Number，用于标识数据包的顺序和唯一性。当一个数据包丢失或损坏时，接收方可以通过Packet Number来判断数据包是否已经接收过，从而避免重复接收。
2. **使用Acknowledge Range：**QUIC协议中的ACK包不仅包含确认已经接收的数据包的Packet Number，还包含一个Acknowledge Range，用于指示未接收到的数据包的Packet Number范围。这样，发送方就可以知道哪些数据包没有被接收，从而可以重传这些数据包，实现快速恢复。
3. **使用时间戳：**QUIC协议中每个数据包都有一个时间戳，用于标识数据包的发送时间。当一个数据包丢失或损坏时，接收方可以通过时间戳判断数据包是否已经过期，从而避免接收到旧的数据包。

#### 拥塞控制

1. **基于令牌桶算法：**QUIC协议中，发送方维护一个令牌桶，用于限制发送速率。每次发送数据包时，发送方必须先获取一个令牌，如果令牌桶中没有足够的令牌，则不能发送数据包，从而避免了发送速率过快导致的网络拥塞。
2. **基于拥塞窗口：**QUIC协议中，每个数据包都有一个拥塞窗口大小，用于限制发送方发送的数据包数量和大小。发送方根据收到的ACK包和拥塞控制算法计算出下一次发送数据包的拥塞窗口大小，并动态调整发送速率和窗口大小，避免拥塞和网络阻塞。
3. **基于慢启动和拥塞避免：**QUIC协议中，发送方在连接建立后采用慢启动算法，逐步增加拥塞窗口大小，以便在网络拥塞时找到最适合的发送速率。同时，在拥塞窗口达到一定大小时，发送方采用拥塞避免算法，逐步增加拥塞窗口大小，以避免网络拥塞和阻塞。



## 二、TCP

### 流量控制

![](/Networker/tcp3.png)

用滑动窗口控制发送方发送速率，防止发送过快服务端来不及接收。
**tcp发送方的滑动窗口会在自身拥塞控制窗口和接收方的接收窗口中选最小者**
滑动窗口如何工作的呢？
1.假设当前滑动窗口大小为4，先发送四个报文段给主机b，主机b进行接收并进行累计确认收到的报文段。
    此时假设报文3在网络传输过程中丢失，主机b会给主机a发送确认报文，然后对3之前的报文进行累计确认，然后调整rwnd窗口大小。
    主机a、在收到主机b报文后，滑动窗口向前移动3-7，由于3是已发送数据，若重传计时器超时，会重传3报文，然后会将累计确认的1和2从发送缓存中移除
2.当主机b接收窗口设为0的时候，滑动窗口大小为0无法再发送数据。此时主机a会一直等待主机b发送非0窗口的通知
3.当主机b接收缓存又有存储空间时，主机b像主机发送非0窗口通知。
    在这个过程中有一个死锁问题：即主机b发送的非0窗口通知在网络传输过程中丢失，主机a会一直处于等待非0窗口通知，主机b会一直等待主机a发送数据。
    **为了解决该问题，tcp为每个连接设有一个持续tcp，当主机a接收到0窗口通知就启动持续计时器，如果持续计时器超时主机a就发送一个0窗口探测报文，而主机b在接收并确认探测报文时会给出自己的滑动窗口大小，此时如果主机b给的接收窗口还是0就重新启动一个持续计时器。如果不是0则死锁局面打破。**
    ::: tip
        1.对于0窗口探测报文和紧急报文段即使主机b是窗口为0也会接收该报文
        2.0窗口探测报文也存在计时器，以防止探测报文丢失，当计时器超时重传探测报文。
    :::

![](/Networker/tcp4.png)

### 拥塞控制

![](/Networker/tcp1.png)

什么是拥塞？**当对网络中某一资源的需求超过了该资源所能提供的可用部分**这种情况就是拥塞
    理想拥塞控制是，当输入负载持续增大吞吐量一直保持最大状态
    当输入负载持续增大，网络吞吐量减小此时进入拥塞状态，当吞吐为0则死锁

接下来对拥塞控制的讨论在如下条件进行：
    1.数据但防线传送，另一方向只传送确认
    2.接收方有足够大的缓存空间，发送窗口只有拥塞程度决定
    3.以最大报文段MSS的个数作为讨论问题单位，非字节
1.主机a要维护一个拥塞窗口，窗口大小取决于网络拥塞程度
    维护原则：当没有出现拥塞就持续增大拥塞窗口，一旦出现拥塞就减小
    拥塞依据：发生超时重传
    初始阶段主机a将拥塞窗口作为发送窗口大小swnd=cwnd 拥塞窗口等于滑动窗口大小。并维护一个ssthresh的慢开始门限
    当拥塞窗口小于ssthresh慢开始门限时采用慢开始算法
    当拥塞窗口大于ssthresh慢开始门限时采该用拥塞避免算法
    当拥塞窗口等于ssthresh慢开始门限时既可以采用慢开始也可以采用拥塞避免算法

#### 慢开始

1.设ssthresh慢开始门限初始值为16，发送窗口大小初始值为1。
2.在每次传输轮次结束后（即发送后优收到确认这种往返过程）发送方会将拥塞窗口不断✖️2的传输直到窗口大小变成门限值（也就是按指数方式增长）
3.当增大到门限值时改用拥塞避免算法

**慢开始指的是一开始传输的报文少，而不是拥塞窗口增长速度**



#### 拥塞避免

 **拥塞避免是指将拥塞窗口从指数增长改为线性增长，使网络不容易出现拥塞，并不一定能避免拥塞。**
1.当增长到门限值后拥塞窗口每次加1开始线性增长拥塞窗口大小。
2.直到出现拥塞即重传计时器超时，此时进入拥塞避免算法，此时假设窗口大小为24时发生超时重传。
3.将ssthresh更新为发送拥塞时拥塞窗口的一半，即12。
4.重新执行慢开始。

#### 快重传

有时个别报文段会在网络中丢失，但实际上网络并未发生拥塞。，发送方会重新执行慢开始，把拥塞窗口又设置为最小值1，降低了传输效率。
为了解决上面的问题采用快重传方法，让对方早知道个别报文段丢失，而不必等到超时重传。
1.例如当主机a发送1-4个报文段，但发送3时发生丢失时，当发送方发送4时接受方发现没有按序收到3，就会直接发送重复确认报文，**当发送方收到连续3个重复确认就会将相应报文立即重传**而不必等待超时重传
2.当发生快重传时，发送发其实就知道了只是丢失了个别报文段并不是发生了拥塞，于是不启动慢开始算法，而启动快恢复算法。

#### 快恢复

发送方将慢开始门限ssthresh值和拥塞窗口cwnd值调整为当前窗口值的一半并直接开始执行拥塞避免算法
个别快恢复算法将门限值调的比一半大 ssthresh += 3
    这样做的原因是，发送方既然能收到三个重复确认，就说明在丢失的报文段后又发送了三个报文段，而这三个报文段会在接受方的缓存中，不会消耗网络资源。所以网络中并没有堆积三个报文段相反还减少了三个报文段因此可以适当增大拥塞窗口

![](/Networker/tcp2.png)



### tcp的建立

每个链接都是从`CLOSED`状态开始的，当它执行一个主动打开连接操作或者被动打开连接操作，它就离开了`CLOSED`状态。

当客户端开始寄第一封信的时候，链接从`CLOSED`状态进入`SYN-SENT状态`，TCP头部携带`SYN=1`表示我要跟服务端建立同步链接、`seq=x`表示这次发送的是序号为x的数据报、`ACK=0`表示还未被确认的数据报，将这三个同时发给服务端

服务端成功收到信后，`CLOSED`状态关闭并进入`SYN-RCVD状态`，表示第一次握手成功，此时服务端知道客户端具有寄信的功能，但不知道的是客户端是否有收信的功能。

这时服务端开始回信，第二次握手发生了，服务端的信携带TCP头部的信息`SYN=1`表示我要跟客户端建立同步链接，`seq=y`表示这次发送的是序号为y的数据报、`ACK=1`表示客户端的信被确认的数据报、`ack=x+1`表示序号为x的数据报已经收到，麻烦下次给我发x+1序号的数据报，当客户端成功收到服务端的回信后，第二次握手成功。

客户端此时已经知道服务端可以收到自己的信，但是服务端并不知道客户端已经收到自己的信，所以客户端需要再次写封信告诉服务端，这时第三次握手发生了，当服务端收到客户端的信后，此时双方都具有寄信和收信的能力，这一刻两人的连接就建立成功了，连接状态就变成`ESTAB-LISHED`，表示正常的传输状态，可以互相交流了。

**总结：**第一次握手确认客户端发送能力 第二次握手确认服务端接受接收和发送能力，第三次握手确认客户端接受能力。然后建立连接


#### tcp为什么不能二次握手

假设我们客户端发送的请求滞留在网络中，然后超时重传了，客户端收到超时重传的请求后与客户端建立连接，然后连接使用完后连接释放，此时如果之前滞留在网络中的请求突然打到了服务器，服务器会直接发送确认报文段，然后建立请求，可是客户端却没有资源要发送，服务端建立连接后白白等待



### tcp的连接释放

![](/Networker/tcp5.png)

客户端发出释放连接的报文这就是`第一次挥手`，TCP头部有一个特殊的信息`FIN(finish，表示想结束了)`，当`FIN=1`时，说明这次的数据报准备销毁连接了，发送成功后，客户端的状态从`ESTAB-LISHED`变为`FIN-WAIT-1`，表示客户端已经说完话结束连接了，看线条1️⃣。

当服务端收到客户端的信之后，此时服务端的状态从`ESTAB-LISHED`变为`CLOSE-WAIT`，表示客户端已经发起了关闭连接。随后服务端写了一封信，这时候`ACK=1`表示收到客户端的信了，用于确认数据报，这是`第二次挥手`，用线条2️⃣表示，当客户端成功收到服务端的信后，客户端的状态从`FIN-WAIT-1`变为`FIN-WAIT-2`，表示服务端同意释放连接。由于服务端还没有发起断开连接请求，此时服务端依然可以进行数据传输，图中绿色箭头表示书婷说最后的几句话。

服务端此时没有数据需要发送了就也会发起释放连接的请求，这是`第三次挥手`，TCP头部包含了`FIN=1`，说明服务端说完了，准备结束了，服务端的状态从`CLOSE-WAIT`变为`LAST-ACK`，表示所有数据报都结束了，用线条3️⃣表示

当客户端收到了服务端来信后，客户端也知道了服务端的话也说完了，也准备结束了，客户端将TCP头部的`ACK=1`表示确认收到服务端的数据报，这是第四次挥手，用线条4️⃣表示

图中有个特别重要的点，就是状态`TIME-WAIT`表示等待所有数据报结束，左边还有一个`2MSL`，`MSL`是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，`2MSL`相当于是数据一个来回的时间，这里为什么要等待这个时间呢？主要是因为发送数据报不可能每次都成功，也有失败的时候，失败就需要重新发送，直到数据报被确认，这里假设第四次挥手线条4️⃣失败，没有发送成功，也没有等待`2MSL`时间直接关闭进入`CLOSED`状态，这时候服务端会认为客户端没有收到自己的信，路途中丢失了，那么会再次发送，但是客户端已经处于`CLOSED`关闭状态了，这样会造成服务端不停的发送，但客户端始终确认不了，所以服务端的连接没有办法释放，迟早奔溃了。


#### 为什么不能三次挥手或更多次

首先四次挥手已经够了，再多就没必要了。
		为什么不是三次挥手？
   		 tcp服务端在发送连接释放报文后进入LAST-ACK状态，客户端在收到该报文后给服务端发送确认报文段进入关闭状态而不是时间等待状态的话，如果该报文丢失了，服务端始终收不到确认报文就会反复重重连接释放报文，而由于客户端直接进入了关闭状态就导致，服务端一直发送连接释放报文并得不到响应。
    **因此时间等待状态以及两倍MSL的长可以确保收到最后一个确认报文段并进入关闭状态。2MSL时常能够保证本次连接所产生的报文段都从网络中消失，不至于出现新的tcp连接中出现旧的报文段。**



### 保活计时器

如果tcp连接在建立后客户端出现故障，无法接发消息，为了防止服务端一直等待白白浪费资源，每次服务器进程在收到客户端的数据都会启动一个保活计时器（2小时），若周期内未收到客户端的数据，服务端会给客户端发送探测报文并每隔75s发送一次探测报文，连续十个探测报文未被响应服务端就认为客户端出现故障从而关闭连接
    

## 三、网络攻击



### 1、XSS跨站脚本攻击

**攻击方式**

​	这种攻击方式通过注入恶意HTML,JS代码到网页中

**产生这种攻击原因**

​	1.浏览器本身具有解析和执行js脚本语言的能力，并不会判断代码是否由恶意

​	2.对于应用的输入和输出没有做校验

**分类**

​	1.反射型

​		攻击者将恶意代码放到url中诱惑用户点击，如果url中携带有js而已代码例如`<script>document.cookie</script>`，又或请求其他服务器，就会把一些信息发给恶意服务器

​		特点只执行一次，因此也成为非持久性XSS

​	2.存储型

​		存储型 XSS 会把用户输入的数据 "存储" 在服务器端，当浏览器请求数据时，脚本从服务器上传回并执行。这种 XSS 攻击具有很强的稳定性。比较常见的一个场景是攻击者在社区或论坛上写下一篇包含恶意 JavaScript 代码的文章或评论，文章或评论发表后，所有访问该文章或评论的用户，都会在他们的浏览器中执行这段恶意的 JavaScript 代码。

​	3.dom型

​		基于 DOM 的 XSS 攻击是指通过恶意脚本修改页面的 DOM 结构，是纯粹发生在客户端的攻击。

如何预防？

* 正则校验
* 如果使用的cookie则要设置`HttpOnly`

### 2、CSRF

跨站请求伪造：CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。

1. 用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；
1. 在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；

3. 用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；

4. 网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；

5. 浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。

预防方法

* 验证码被认为是对抗 CSRF 攻击最简洁而有效的防御方法。验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。

* Referer Check，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的"源"。

* token验证，在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是    CSRF 攻击而拒绝该请求。

  















<CommentService/>